{
  "hash": "f0d3258b41ef8c9a7468b61043cd0f11",
  "result": {
    "markdown": "---\ntitle: \"Quantifying Suitable Growth Area for Aquaculture Species Along the West Coast\" \ndescription: \"Geospatial Analysis & Remote Sensing Course Project\"\nfreeze: auto\nauthor: \n  - name: Heather Childers\n    url: hmchilders.github.io/\n    affiliation: Master of Environmental Data Science Program\n    affiliation-url: https://bren.ucsb.edu/masters-programs/master-environmental-data-science\n    #orcid: \ndate: 12-9-2023\ncategories: [MEDS, R, Geospatial]\nimage: Graph.png\ncitation: \n  url: hmchilders.github.io/Geospatial_Blogs/2023-12-9\n---\n\n\n# Quantifying Suitable Growth Area for Aquaculture Species Along the West Coast\n\n## Overview\n\nMarine aquaculture has the potential to play an important role in the global food supply as a more sustainable protein option than land-based meat production. Gentry et al. mapped the potential for marine aquaculture globally based on multiple constraints, including ship traffic, dissolved oxygen, bottom depth .\n\nThis exercise uses suitable temperature and depth data for each Exclusive Economic Zones (EEZ) on the West Coast of the US to find the area that are best suited to developing marine aquaculture for several species of oysters.\n\nThis workflow is then expanded to create a function that can take in temperature and depth limits and produce graphs that show the area in square kilometers and the percentage of each EEZ that is suitable for that species' suitable conditions.\n\nThis repository also contains an R script with the finalized function inside.\n\n### Skills used in this workflow:\n\n-   Combining vector/raster data\n\n-   Re-sampling raster data\n\n-   Masking raster data\n\n-   Map algebra\n\n## Data\n\nTo download the data used for this project, check out the link in my [GitHub Repository](https://github.com/hmchilders/Marine_Suitable_Zone_Calculation/tree/main)!\n\n#### Sea Surface Temperature\n\nWe will use average annual sea surface temperature (SST) from the years 2008 to 2012 to characterize the average sea surface temperature within the region. The data we are working with was originally generated from [NOAA's 5km Daily Global Satellite Sea Surface Temperature Anomaly v3.1](https://coralreefwatch.noaa.gov/product/5km/index_5km_ssta.php).\n\n#### Exclusive Economic Zones\n\nWe will be designating maritime boundaries using Exclusive Economic Zones off of the west coast of US from [Marineregions.org](https://www.marineregions.org/eez.php).\n\n#### Bathymetry\n\nTo characterize the depth of the ocean we will use the [General Bathymetric Chart of the Oceans (GEBCO)](https://www.gebco.net/data_and_products/gridded_bathymetry_data/#area).[^1]\n\n[^1]: GEBCO Compilation Group (2022) GEBCO_2022 Grid (<doi:10.5285/e0f0bb80-ab44-2739-e053-6c86abc0289c>).\n\n## Workflow:\n\n### Import Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(here)\nlibrary(tmap)\nlibrary(cowplot)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(devtools)\nlibrary(tmaptools)\nlibrary(maptiles)\n```\n:::\n\n\n### Load Datasets\n\n#### Sea Surface Temperature\n\nRead in the SST Data using the `terra::rast()` function. Make sure you are in the correct working directory when reading in this data. If you are having issues, you can download my Rmarkdown file from my GitHub repository which uses `here()` to make this workflow more reproducible, assuming you followed the same folder structure outlined in the repository README.\n\n\n::: {.cell messages='false'}\n\n```{.r .cell-code}\n#Read in each of the Annual SSTs from 2008-2012\nsst_2008 <- rast('data/average_annual_sst_2008.tif')\nsst_2009 <- rast('data/average_annual_sst_2009.tif')\nsst_2010 <- rast('data/average_annual_sst_2010.tif')\nsst_2011 <- rast('data/average_annual_sst_2011.tif')\nsst_2012 <- rast('data/average_annual_sst_2012.tif')\n\n#Create a rasteer stack from the 5 individual rasters\nsst <- c(sst_2008,\n         sst_2009,\n         sst_2010,\n         sst_2011,\n         sst_2012)\n\n#Plot the raster stack to make sure the data was read in and stacked properly\nplot(sst)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n#### Exclusive Economic Zones\n\nRead in the EEZ data using the `sf::st_read()` function.\n\nIt's important that when we are trying to work with different datatsets, we make sure that they have the same CRS. Take this opportunity to re-project the EEZ data to the same CRS as the SST data so it's easier to manipulate throughout the workflow.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoast <- st_read('data/wc_regions_clean.shp')\n\n#Reproject the coastal data to the same CRS as the SST Data\ncoast <- coast %>% \n  st_transform(crs(sst_2008))\n```\n:::\n\n\n#### Bathymetry\n\nRead in the depth data using the `terra::rast()` function.\n\nIt's important that when we are trying to work with different datatsets, we make sure that they have the same CRS. Take this opportunity to re-project the depth data to the same CRS as the SST data so it's easier to manipulate throughout the workflow.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Read in the depth data and reproject to the same CRS as the SST Data\ndepth <- rast('data/depth.tif') %>% \n  project(crs(sst_2008))\n```\n:::\n\n\n**CRS CHECK:**\n\nCheck that the CRS of all the datasets match before moving on\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Check that all the CRS match\nst_crs(sst) == st_crs(depth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nst_crs(sst) == st_crs(coast)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nst_crs(coast) == st_crs(depth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\n### Clean and Wrangle Data\n\nBased on previous research, we know that oysters needs the following conditions for optimal growth:\n\n-   sea surface temperature: 11-30Â°C\n-   depth: 0-70 meters below sea level\n\nThe next step is to process the SST and depth data so that they can be combined. In this case the SST and depth data have slightly different resolutions, extents, and positions. We don't want to change the underlying depth data, so we will need to resample to match the SST data using the nearest neighbor approach.\n\n1.  Start by creating a single layer that has the average sea surface temperature\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Create a new raster that has the average SST converted to Celcius\nsst_stac <- mean(sst - 273.15) \n\n#Plot the new stack to check that there is only one map in the output and the temp range is reasoanable for Celcuis \nplot(sst_stac)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n2.  Crop depth raster to match the extent of the SST raster\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    #create a bounding box using the extents of the SST data\n    bbox <- st_bbox(sst)\n    #Crop the depth data to just our area of interest\n    depth <- crop(depth, bbox)\n    ```\n    :::\n\n\n3.  Re-sample the depth data to match the resolution of the SST data using the nearest neighbor approach. You can check that the depth and SST match in resolution, extent, and coordinate reference system by stacking the raster layers\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    #Resample the depth data, use method = \"near\" to use the nearest neighbor approach\n    depth_resampl <- resample(depth, y = sst_stac, method = \"near\")\n    \n    #Check that the depth data was resampled by stacking the rasters\n    sst_depth <- c(sst_stac,depth_resampl)\n    \n    #Check our stacked dataset by plotting\n    plot(sst_depth)\n    ```\n    \n    ::: {.cell-output-display}\n    ![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n    :::\n    :::\n\n\n#### Find suitable locations\n\nIn order to find suitable locations for marine aquaculture, we'll need to find locations that are suitable in terms of both SST and depth. We can achieve this by reclassifying the SST and depth data into locations that are suitable for oysters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Create a reclassification matrix for stuitable temperatures\nrcl_temp <- matrix(c(-Inf, 11, NA,\n                     11, 30, 1,\n                     30, Inf, NA ), ncol = 3, byrow = TRUE)\n\n#Reclassify the temperature data\ntemp_reclass <- classify(sst_stac, rcl = rcl_temp)\n#Plot to see the reclassification worked\nplot(temp_reclass)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#Create a reclasification matrix for the suitable depth\nrcl_depth <- matrix(c(-Inf, -70, NA,\n                      -70, 0 , 1,\n                      0, Inf, NA), ncol = 3, byrow = TRUE)\n\n#Reclassify the Depth data\ndepth_reclass <- classify(depth_resampl, rcl = rcl_depth)\n#Plot to see the reclassification worked\nplot(depth_reclass)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n\nThen use the `laap()` function to find the areas that have suitable temperatures and depths for oysters. Using the multiply function inside `lapp()` creates a raster that has 1s where both conditions are TRUE and 0s when one or more conditions are FALSE.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create a function to multiply two inputs\nmultiply = function(x,y){\n  x*y\n}\n#Use Lapp to create an overlay of the reclassified data\noyster_cond <- lapp(c(temp_reclass, depth_reclass), fun = multiply)\n#Plot the overlay to check the area\nplot(oyster_cond, col = 'blue')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### Find the suitable area per EEZ for oysters\n\nNow that our data is cleaned and wrangled, we can begin our analysis to determine the suitable area per EEZ region. Start by using our `oyster_cond` variable to create. amaks of suitable areas. Then use the mask to crop the EEZ data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#transform the coastal data into a raster\ncoast_rast <- rasterize(coast, sst, field = 'rgn')\n#Create a mask using the selected areas for suitable pyster conditions\nmask <- mask(coast_rast, oyster_cond)\n#Use the mask to crop the coastal data to our area of interest (suitable areas)\nEEZ <- crop(mask, coast_rast) \n#Check that the raster was cropped correctly\nplot(EEZ)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nNow we can use the `cellSize()` and `zonal()` finctions to calculcate the total area of each EEZ and the total suiatble areas for oysters in each EEZ\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Use the cellSize function to fin the area of each cell\nEEZ_area <- cellSize(EEZ)\n\n#Use the zonal function to calculate the sum of the suitable areas in each region \nsuit_zones = zonal(EEZ_area, EEZ, fun = 'sum', na.rm = TRUE) \nsuit_zones\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  rgn       area\n1  Central California 4069876613\n2 Northern California  178026784\n3              Oregon 1074271959\n4 Southern California 3757284868\n5          Washington 2378313748\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Use the cellSize function to fin the area of each cell\ntotal_area <- cellSize(coast_rast)\n#Use the zonal function to calculate the sum of the total areas in each region \nzones = zonal(total_area, coast_rast, fun = 'sum', na.rm = TRUE)\nzones\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  rgn         area\n1  Central California 202779854223\n2 Northern California 163715001370\n3              Oregon 179866415384\n4 Southern California 206535860068\n5          Washington  67813688037\n```\n:::\n:::\n\n\nCreate one singular dataframe with the total area per region(km^2^), total suitable area(km^2^), and percentage of suitable area(%)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Add the suitable area stats to the new variable zonal_stats\nzonal_stats <- suit_zones %>% \n  #Rename the area column to suitable area for clarity\n  rename(suitable_area = area) %>% \n  #Convert to km2\n  mutate(suitable_area = (suitable_area/1000000)) %>% \n  #Add a new column ot the dataframe using the total area stats calculated above\n  add_column(zones$area) %>% \n  #Rename that area column to total-area for clarity\n  rename(total_area = 'zones$area') %>% \n  #Convert to km2\n  mutate(total_area = (total_area/1000000)) %>% \n  #Add a new column that calculates the percentage of each region thats suitable\n  mutate(pct_suitable = ((suitable_area/total_area)*100))\n#Print the output of the new dataset\nzonal_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  rgn suitable_area total_area pct_suitable\n1  Central California     4069.8766  202779.85    2.0070419\n2 Northern California      178.0268  163715.00    0.1087419\n3              Oregon     1074.2720  179866.42    0.5972610\n4 Southern California     3757.2849  206535.86    1.8191925\n5          Washington     2378.3137   67813.69    3.5071293\n```\n:::\n\n```{.r .cell-code}\n#Add the geometry to the zonal stats dataset by using a left joim \nzonal_rast <- left_join(coast, zonal_stats, by = 'rgn') \n```\n:::\n\n\n#### Visualize the Results\n\nNow that we have results, we need to present them! Use the super fun package `tmap` to create graph of total suitable area(km^2^), and percentage of suitable area(%) with updated titles, legends, etc.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Create a map to plot the suiatable area in km^2\ntm_shape(zonal_rast)+\n  tm_polygons(fill = 'suitable_area', fill_alpha = 0.6, #Add geometry and opacity\n              fill.scale = tm_scale(breaks = c(0,1000,2000,3000,4000,5000), #Add breaks, and legend title\n                                    values = \"YlGn\"), #Add Color scheme\n              fill.legend = tm_legend(title = 'Suitable Area (km^2)'))+ #Add legend title\n  tm_title(text = \"Suitable Area by Region: Oysters\")+ # Add figure title\n  tm_scalebar(position = c('left','bottom'))+ #Add a scalebar\n  tm_basemap(server = \"OpenStreetMap\") #Add a basemap\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"YlGn\" is named\n\"brewer.yl_gn\"\nMultiple palettes called \"yl_gn\" found: \"brewer.yl_gn\", \"matplotlib.yl_gn\". The first one, \"brewer.yl_gn\", is returned.\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nâ¹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Create a map to show the percent suitable area\ntm_shape(zonal_rast)+\n  tm_polygons(fill = 'pct_suitable', fill_alpha = 0.7, #Add geometry and opacity\n              fill.scale = tm_scale(breaks = c(0,0.5,1,2,3,4), #Add breaks\n                values = \"YlGn\"), #Add color scheme\n              fill.legend = tm_legend(title = 'Suitable Area(%)'))+ #Add legend title\n  tm_title(text = \"Suitable Area by Region: Oysters\")+ #Add figure title\n  tm_scalebar(position = c('left','bottom'))+ #Add a scalebar\n  tm_basemap(server = \"OpenStreetMap\") #Add a basemap\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n#### Broaden the workflow:\n\nNow that we've developed a workflow for one group of species, we can update the workflow to create a function that would allow you to reproduce your results for other species.\n\nRun the function for a species of your choice! You can find information on species depth and temperature requirements on [SeaLifeBase](https://www.sealifebase.ca/search.php).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspecies_suitable_area = function(species_name, min_temp_C, max_temp_C, min_depth_m, max_depth_m){\n  #Create a reclassification matrix for Temperature\n  rcl_temp <- matrix(c(-Inf, min_temp_C, NA,\n                     min_temp_C, max_temp_C, 1,\n                     max_temp_C, Inf, NA ), ncol = 3, byrow = TRUE)\n  #Reclassify the temp data\n  temp_reclass <- classify(sst_stac, rcl = rcl_temp)\n  #Create a reclassification matrix for depth\n  rcl_depth <- matrix(c(-Inf, (max_depth_m*(-1)), NA,\n                      (max_depth_m*(-1)), (min_depth_m*(-1)), 1,\n                      (min_depth_m*(-1)), Inf, NA), ncol = 3, byrow = TRUE)\n  #reclassify the depth data\n  depth_reclass <- classify(depth_resampl, rcl = rcl_depth)\n    #Create a function to multiply two outputs\n    multiply = function(x,y){\n    x*y\n    }\n    #Use lapp() to create an overlay from the product of the two reclassified datasets\n  species_cond <- lapp(c(temp_reclass, depth_reclass), fun = multiply)\n  #Make a mask from the overlay\n  mask <- mask(coast_rast, species_cond)\n  #Use the mask to crop the coastal data to our area of interest (suitable areas)\n  EEZ <- crop(mask, coast_rast) \n  #Use the cellSize function to fin the area of each cell\n  EEZ_area <- cellSize(EEZ)\n  #Use the zonal function to calculate the sum of the suitable areas in each region \n  suit_zones = zonal(EEZ_area, EEZ, fun = 'sum', na.rm = TRUE) \n  #Use the cellSize function to fin the area of each cell\n  total_area <- cellSize(coast_rast)\n  #Use the zonal function to calculate the sum of the total areas in each region \n  fun_zones <<- zonal(total_area, coast_rast, fun = 'sum', na.rm = TRUE)\n  \n  #Add the suitable area stats to the new variable zonal_stats\n  zonal_stats <- suit_zones %>% \n  #Rename the area column to suitable area for clarity\n  rename(suitable_area = area) %>% \n  #Convert to km2\n  mutate(suitable_area = (suitable_area/1000000)) %>% \n  #Add a new column to the dataframe using the total area stats calculated above\n  add_column(fun_zones$area) %>% \n  #Rename that area column to total-area for clarity\n  rename(total_area = 'fun_zones$area') %>% \n  #Convert to km2\n  mutate(total_area = (total_area/1000000)) %>% \n  #Add a new column that calculates the percentage of each region thats suitable\n  mutate(pct_suitable = ((suitable_area/total_area)*100))\n\n  #Add the geometry to the zonal stats dataset by using a left joim \n  zonal_rast <- left_join(coast, zonal_stats, by = 'rgn') \n  \n  area_plot<- tm_shape(zonal_rast)+\n  tm_polygons(fill = 'suitable_area', fill_alpha = 0.6, #Add geometry and opacity\n              fill.scale = tm_scale(values = \"YlGn\"), #Add Color scheme\n              fill.legend = tm_legend(title = 'Suitable Area (km^2)'))+ #Add legend title\n  tm_title(text = paste0(\"Suitable Area by Region: \", species_name))+ # Add figure title\n  tm_scalebar(position = c('left','bottom'))+ #Add a scalebar\n  tm_basemap(server = \"OpenStreetMap\") #Add a basemap\n  \n  pct_plot <- tm_shape(zonal_rast)+\n  tm_polygons(fill = 'pct_suitable', fill_alpha = 0.7, #Add geometry and opacity\n              fill.scale = tm_scale(values = \"YlGn\"), #Add color scheme\n              fill.legend = tm_legend(title = 'Suitable Area(%)'))+ #Add legend title\n  tm_title(text = paste0(\"Suitable Area by Region: \", species_name))+ #Add figure title\n  tm_scalebar(position = c('left','bottom'))+ #Add a scalebar\n  tm_basemap(server = \"OpenStreetMap\") #Add a basemap\n  \n  return(list(area_plot,pct_plot))\n\n}\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}